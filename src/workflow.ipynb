{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f15d59",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "A simple **Chat-with-Multi PDFs / Docs** app for **Retrieval-Augmented Generation (RAG)**.  \n",
    "It allows you to ask questions about the contents of PDFs and DOC files, and the app will provide relevant responses.\n",
    "\n",
    "![Chatbot Diagram](../src/images/graphWorkFlow.jpg)\n",
    "\n",
    "This app is built using [**LangGraph**](https://www.langchain.com/langgraph) and [**LangChain**](https://www.langchain.com/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0fefeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Setting\n",
    "import os \n",
    "import dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "os.environ['GOOGLE_API_KEY'] = dotenv.get_key(key_to_get='GOOGLE_API_KEY', dotenv_path='.env')\n",
    "llm = init_chat_model(model = 'gemini-2.5-flash' , model_provider='google-genai')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da3005b",
   "metadata": {},
   "source": [
    "# A. Preprocess documents\n",
    "\n",
    "- In this step we read files to get the full text and split them into small chunks and embed them to store in Vectore DataBase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5748e75",
   "metadata": {},
   "source": [
    "##### 1) Reading Files using PyPDF2 to extract text from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845de5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def get_content_pages(files:  list[str]) -> str:\n",
    "    \"\"\"Read PDF or TXT files and return their combined text\"\"\"\n",
    "    ftext = \"\"\n",
    "    for file_path in files:\n",
    "        if file_path.lower().endswith(\".pdf\"):\n",
    "            pdf_loader = PdfReader(file_path)\n",
    "            for page in pdf_loader.pages:\n",
    "                ftext += page.extract_text() or \"\"  \n",
    "        else:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                ftext += f.read()\n",
    "        ftext += \"\\n\"\n",
    "    return ftext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d16b1",
   "metadata": {},
   "source": [
    "##### 2) Split Full text into small chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4f1aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def split_chunks(text : str , chunk_size :int = 600, chunk_overlap : int = 50) :\n",
    "    \"\"\"Split to small and overla chunks\"\"\"\n",
    "    splitter= RecursiveCharacterTextSplitter(\"\\n\", chunk_size =chunk_size , \n",
    "                                         chunk_overlap =chunk_overlap)\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af101dd1",
   "metadata": {},
   "source": [
    "##### 3) Initialize Vector Database\n",
    "\n",
    "1. Generate embeddings from chunks using the **[MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)** model from SentenceTransformers.\n",
    "\n",
    "2. Store the embeddings in a vector database using **Chroma** from LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9326b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import InMemoryVectorStore\n",
    "\n",
    "\n",
    "def create_vectorDB(chunks : list[str] ,\n",
    "                    embedding_name  : str = \"sentence-transformers/all-MiniLM-L6-v2\" ) : \n",
    "    \"\"\"Generate and store embedding of chunks into vector database\"\"\"\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name = embedding_name)\n",
    "    vectordb = InMemoryVectorStore.from_texts(chunks , embedding_model)\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a14f2f",
   "metadata": {},
   "source": [
    "##### 4) concate components together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbd992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessDocuments(files:list[str]) :\n",
    "    \"\"\"concat all together\"\"\" \n",
    "    \n",
    "    content = get_content_pages(files=files)\n",
    "    chunks = split_chunks(content)\n",
    "    vectorDB = create_vectorDB(chunks)\n",
    "    return vectorDB , chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3e8f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\szeya\\AppData\\Local\\Temp\\ipykernel_33700\\2406254441.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name = embedding_name)\n",
      "c:\\Users\\szeya\\miniconda3\\envs\\chat\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# testing functions\n",
    "pdfs = [os.path.join('data' , x) for x in os.listdir(\"data\")]  #pdf paths\n",
    "vector_db ,chunks = ProcessDocuments(pdfs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba43e806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------- *1* ---------------------------------------------\n",
      "So we call this supervised learning because we're supervising the algorithm or, in other \n",
      "words, we're giving the algorithm the, quote,  right answer for a number of houses. And \n",
      "then we want the algorithm to learn the a ssociation between the inputs and the outputs \n",
      "and to sort of give us more of the right answers, okay?  \n",
      "It turns out this specific exam ple that I drew here is an example of something called a \n",
      "regression problem. And the term regression sort of refers to the fact that the variable \n",
      "you're trying to predict is a continuous value and price.\n",
      "--------------------------------------------- *2* ---------------------------------------------\n",
      "means. So on the upper left where the m ouse pointer is moving, this horizontal line \n",
      "actually shows the human steering direction, and this white bar, or this white area right \n",
      "here shows the steering direction chosen by the human driver, by moving the steering \n",
      "wheel.  \n",
      "The human is steering a little bit to the left here indicated  by the position of this white \n",
      "region. This second line here wh ere Mamos is pointing, the sec ond line here is the output \n",
      "of the learning algorithm, and where the learni ng algorithm currently thinks is the right\n",
      "--------------------------------------------- *3* ---------------------------------------------\n",
      "into four major sections. We're gonna talk about four major topics in this class, the first \n",
      "of which is supervised learning. So le t me give you an example of that.  \n",
      "So suppose you collect a data set of housing prices. And one of the TAs, Dan Ramage, \n",
      "actually collected a data set for me last week to use in the example later. But suppose that \n",
      "you go to collect statistics about how much hous es cost in a certain geographic area. And \n",
      "Dan, the TA, collected data from housing pr ices in Portland, Oregon. So what you can do\n"
     ]
    }
   ],
   "source": [
    "query = \"what is supervise learning?\" \n",
    "similar_docs = vector_db.similarity_search(query, k=3)\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(\"---\" * 15, f\"*{i+1}*\", \"---\" * 15)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d2d2e",
   "metadata": {},
   "source": [
    "# B. Work-Flow-Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383e067",
   "metadata": {},
   "source": [
    "## 1) Define StateClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e2c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class MyState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    detected_lang: str\n",
    "    dialect: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c32a810",
   "metadata": {},
   "source": [
    "## 2) Generate a Retriever Tool using LangChain\n",
    "\n",
    "- Use `create_retriever_tool` from **LangChain** to generate a retriever tool from the vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95436b8",
   "metadata": {},
   "source": [
    "##### 2.1) retriever_tool Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a7d73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So we call this supervised learning because we're supervising the algorithm or, in other \n",
      "words, we're giving the algorithm the, quote,  right answer for a number of houses. And \n",
      "then we want the algorithm to learn the a ssociation between the inputs and the outputs \n",
      "and to sort of give us more of the right answers, okay?  \n",
      "It turns out this specific exam ple that I drew here is an example of something called a \n",
      "regression problem. And the term regression sort of refers to the fact that the variable \n",
      "you're trying to predict is a continuous value and price.\n",
      "\n",
      "means. So on the upper left where the m ouse pointer is moving, this horizontal line \n",
      "actually shows the human steering direction, and this white bar, or this white area right \n",
      "here shows the steering direction chosen by the human driver, by moving the steering \n",
      "wheel.  \n",
      "The human is steering a little bit to the left here indicated  by the position of this white \n",
      "region. This second line here wh ere Mamos is pointing, the sec ond line here is the output \n",
      "of the learning algorithm, and where the learni ng algorithm currently thinks is the right\n",
      "\n",
      "into four major sections. We're gonna talk about four major topics in this class, the first \n",
      "of which is supervised learning. So le t me give you an example of that.  \n",
      "So suppose you collect a data set of housing prices. And one of the TAs, Dan Ramage, \n",
      "actually collected a data set for me last week to use in the example later. But suppose that \n",
      "you go to collect statistics about how much hous es cost in a certain geographic area. And \n",
      "Dan, the TA, collected data from housing pr ices in Portland, Oregon. So what you can do\n",
      "\n",
      "buy or movies for you to rent or whatever , these are other examples of learning \n",
      "algorithms that have learned what sorts of th ings you like to buy or what sorts of movies \n",
      "you like to watch and can therefore give  customized recommendations to you.  \n",
      "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \n",
      "to explain to me some learning algorithm in th e innards of my car th at's sort of doing its \n",
      "best to optimize my driving performan ce for fuel efficiency or something.\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool \n",
    "\n",
    "retriver = vector_db.as_retriever()\n",
    "retrivertool = create_retriever_tool(retriver , \n",
    "                                     \"retriever_tool\" ,\n",
    "                                     \"Search and return information about input context\" )\n",
    "\n",
    "print(retrivertool.invoke({\"query\": query}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fa9197",
   "metadata": {},
   "source": [
    "##### 2.2) retriever Agient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b881946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "RetriverAgent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[retrivertool],\n",
    "    name=\"RetriverAgent\",\n",
    "    prompt=(\n",
    "        \"You are a retriever agent.\\n\"\n",
    "        \"- Otherwise, always call the retriever_tool with the user query.\\n\"\n",
    "        \"- Return ONLY the page_content of the retrieved documents.\\n\"\n",
    "        \"- Do not summarize or rephrase.\\n\"\n",
    "        \"- Don't return repeated retrieved chunks.\\n\"\n",
    "        \"- If you didn't find similar text return 'I can't find it'.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b8abf",
   "metadata": {},
   "source": [
    "## 3) Detect Language and Dialect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed5a5e3",
   "metadata": {},
   "source": [
    "##### 3.1) Detect Language using Prompt Template with structure ouput and Dialect if the query language is ar\n",
    "\n",
    "#####  Detect Arabic dialect\n",
    "\n",
    "- Using [IbrahimAmin/marbertv2-arabic-written-dialect-classifier](https://huggingface.co/IbrahimAmin/marbertv2-arabic-written-dialect-classifier)  \n",
    "- The model predicts one of **5 Arabic dialects**:\n",
    "\n",
    "| Code | Dialect | Region / Notes |\n",
    "|------|---------|----------------|\n",
    "| MAGHREB | Maghreb dialect | Northwest Africa (Morocco, Algeria, Tunisia, Libya, Mauritania) |\n",
    "| LEV     | Levantine dialect | Lebanon, Syria, Jordan, Palestine |\n",
    "| MSA     | Modern Standard Arabic | Formal Arabic (books, news, official use) |\n",
    "| GLF     | Gulf dialect | Saudi Arabia, UAE, Kuwait, Bahrain, Qatar, Oman |\n",
    "| EGY     | Egyptian dialect | Egypt |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21fafd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from pydantic import Field, BaseModel\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "class LanguageDetector(BaseModel):\n",
    "    language: str = Field(\n",
    "        description=\"Detected language of the question, represented in a two-character ISO 639-1 code.\"\n",
    "    )\n",
    "\n",
    "\n",
    "dialect_model_name = \"IbrahimAmin/marbertv2-arabic-written-dialect-classifier\"\n",
    "\n",
    "dialect_pipeline = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=AutoModelForSequenceClassification.from_pretrained(dialect_model_name),\n",
    "    tokenizer=AutoTokenizer.from_pretrained(dialect_model_name),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def detecting_language(state: MyState):\n",
    "    \n",
    "   \n",
    "    question = state['messages'][0].content\n",
    "    \n",
    "    detectionmodel = llm.with_structured_output(LanguageDetector)\n",
    "\n",
    "    LANGUAGE_DETECTOR_TEMPLATE = \"\\n\\n\".join([\n",
    "        \"You are a language detector assessing to return the language of the question from a user.\",\n",
    "        \"Here is the user question: {question}\",\n",
    "        \"# Instructions:\",\n",
    "        \"- Return only the two-character ISO 639-1 code for the language.\",\n",
    "        \"- Base detection on the language of the question itself (its structure and wording), not on individual foreign words inside it.\",\n",
    "        \"- Focus especially on the interrogative word (e.g., what, how, من, ماذا) and the main verb or auxiliary verb.\"\n",
    "    ])\n",
    "\n",
    "\n",
    "    detection_prompt = PromptTemplate(\n",
    "        template=LANGUAGE_DETECTOR_TEMPLATE,\n",
    "        input_variables=[\"question\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    prompt = detection_prompt.format(question=question)\n",
    "    response: LanguageDetector = detectionmodel.invoke(prompt)\n",
    "\n",
    "\n",
    "    # dialect\n",
    "    dialect = None\n",
    "    if response.language == \"ar\":\n",
    "        preds = dialect_pipeline(question, top_k=None)\n",
    "        if preds:\n",
    "            best = max(preds, key=lambda x: x[\"score\"])\n",
    "            dialect = best[\"label\"]\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"],\n",
    "        \"detected_lang\": response.language,\n",
    "        \"dialect\": dialect\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1e292e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic Question: ('ar', 'MSA')\n",
      "--------------------------------------------------\n",
      "English Question: ('en', None)\n",
      "--------------------------------------------------\n",
      "French Question: ('fr', None)\n",
      "--------------------------------------------------\n",
      "Spanish Question: ('es', None)\n",
      "--------------------------------------------------\n",
      "German Question: ('de', None)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "from langchain_core.messages import HumanMessage\n",
    "import time\n",
    "\n",
    "examples = [\n",
    "    (\"Arabic Question\", MessagesState(messages=[HumanMessage(content=\"ما هي أنواع Transformer؟\")])),\n",
    "    (\"English Question\", MessagesState(messages=[HumanMessage(content=\"What are the types of Transformer?\")])),\n",
    "    (\"French Question\", MessagesState(messages=[HumanMessage(content=\"Qu'est-ce qu'un transformateur?\")])),\n",
    "    (\"Spanish Question\", MessagesState(messages=[HumanMessage(content=\"¿Cuáles son los tipos de transformadores?\")])),\n",
    "    (\"German Question\", MessagesState(messages=[HumanMessage(content=\"Welche Arten von Transformatoren gibt es?\")])) ,\n",
    "]\n",
    "\n",
    "\n",
    "for name, state in examples:\n",
    "    result = detecting_language(state)\n",
    "    print(f\"{name}: {result['detected_lang'] ,result['dialect'] }\")\n",
    "    print(\"-\" * 50)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accf8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGY Example: ('ar', 'EGY')\n",
      "--------------------------------------------------\n",
      "LEV Example 2: ('ar', 'LEV')\n",
      "--------------------------------------------------\n",
      "GLF Example: ('ar', 'GLF')\n",
      "--------------------------------------------------\n",
      "LEV Example: ('ar', 'LEV')\n",
      "--------------------------------------------------\n",
      "MSA Example: ('ar', 'MSA')\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "import time\n",
    "\n",
    "examples = [\n",
    "    (\"EGY Example\", MessagesState(messages=[HumanMessage(content=\"ازيك يصحبي قولي انواع l\")])),\n",
    "    (\"LEV Example 2\", MessagesState(messages=[HumanMessage(content=\"عامل اي يازلمي اليوم ممكن تقولي types of ML\")])),\n",
    "    (\"GLF Example\", MessagesState(messages=[HumanMessage(content=\"شلونك يا طويل العمر؟ ممكن تقول لي examples of ML\")])),\n",
    "    (\"LEV Example\", MessagesState(messages=[HumanMessage(content=\"كيفك يا زلمي؟ شو الأخبار؟ give me types of ML\")])),\n",
    "    (\"MSA Example\", MessagesState(messages=[HumanMessage(content=\"ما هي أنواع   ML techniques؟\")]))\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for name, state in examples:\n",
    "    result = detecting_language(state)\n",
    "    print(f\"{name}: {result['detected_lang'] ,result['dialect'] }\")\n",
    "    print(\"-\" * 50)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f172ea",
   "metadata": {},
   "source": [
    "## 4) Translate Query to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8d73a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "def TranslateQuery(state :MyState):\n",
    "    \n",
    "    \"Machine Translation to translate Queries to english text\"\n",
    "    \n",
    "    user_messages = [m for m in state[\"messages\"] if isinstance(m,HumanMessage)]\n",
    "    question = state.get(\"translated_query\", user_messages[-1].content)\n",
    "\n",
    "    msg_prompt = f\"\"\"\n",
    "                    You are a Machine Translation (MT) system.\n",
    "                    Your task: translate the user question to English text.\n",
    "\n",
    "                    Instructions:\n",
    "                    1. Translate the question to English as accurately as possible.\n",
    "                    2. Do not add explanations, comments, or extra content.\n",
    "                    3. Do not attempt to clarify or modify the meaning.\n",
    "                    4. Keep the original meaning exactly.\n",
    "\n",
    "                    User question: \"{question}\"\n",
    "                    \"\"\"\n",
    "\n",
    "    prompt_msg_template = PromptTemplate(\n",
    "        template=msg_prompt,\n",
    "        input_variables=['question']\n",
    "    )\n",
    "\n",
    "    resonong = llm.invoke([{'role': 'user', 'content': prompt_msg_template.format(question=question)}])\n",
    "\n",
    "    return {'messages': [HumanMessage(content=resonong.content)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd5fd268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you differentiate between types of transformers?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "input_state = {\n",
    "    \"messages\": convert_to_messages([\n",
    "        {\"role\": \"user\", \"content\": \"تقدر تفرق بين انواع transformers \"}\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "response = TranslateQuery(input_state)\n",
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1be0803",
   "metadata": {},
   "source": [
    "## 5) Grader\n",
    "- Grander is a score computed from llm to determine whether the retrieved documents are relevant to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e612d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel , Field\n",
    "from typing import Literal\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "\n",
    "class GraderDocument(BaseModel):\n",
    "    \"\"\"Grade documents using a binary score for relevance check.\"\"\"\n",
    "    binary_score : str = Field(description= \"Relevance score: 'yes' if relevant, or 'no' if not relevant\")\n",
    "\n",
    "\n",
    "def GraderDocumentAgent(state: MyState)-> Literal['Chit-ChatAgent' ,'AnswerAgent'] :\n",
    "    \n",
    "    user_messages = [m for m in state[\"messages\"] if isinstance(m, HumanMessage)]\n",
    "    question = state.get(\"translated_query\", user_messages[-1].content)\n",
    "    context = state['messages'][-1].content\n",
    "\n",
    "      \n",
    "    gradermodel = llm.with_structured_output(GraderDocument)\n",
    "    \n",
    "    GRADE_PROMPT = \"\\n\\n\".join([\n",
    "    \"You are a grader assessing relevance of a retrieved document to a user question.\",\n",
    "    \"Here is the retrieved document: \\n\\n {context}\",\n",
    "    \"Here is the user question: {question}\",\n",
    "    \"If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\",\n",
    "    \"If the question is an introductory or personal question (e.g., greetings like 'how are you', or self-introduction like 'I am X'), always grade it as 'yes'.\",\n",
    "    \"Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\" ])\n",
    "    \n",
    "    prompt = PromptTemplate(template= GRADE_PROMPT , input_variables=['question', 'context'])\n",
    "    \n",
    "    \n",
    "    prompt_template = prompt.format(question = question , context = context)\n",
    "    response =  gradermodel.invoke(\n",
    "        [HumanMessage(content=prompt_template) ]\n",
    "    )\n",
    "\n",
    "    score = response.binary_score\n",
    "    \n",
    "    if score == 'yes' :\n",
    "        return \"AnswerAgent\"\n",
    "    else : \n",
    "        return 'Chit-ChatAgent'\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f82013ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chit-ChatAgent'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What does machine learning?\",\n",
    "            },\n",
    "            \n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"retriever_tool\",\n",
    "                        \"args\": {\"query\": \"Supervised learning, Unsupervised learning, Reinforcement learning.\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\"role\": \"tool\", \"content\": \"meow\", \"tool_call_id\": \"1\"},\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "GraderDocumentAgent(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69180bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AnswerAgent'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What does machine learning?\",\n",
    "            },\n",
    "            \n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"retriever_tool\",\n",
    "                        \"args\": {\"query\": \"Supervised learning, Unsupervised learning, Reinforcement learning.\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\"role\": \"tool\", \n",
    "             \"content\": \"\"\"Machine learning is a field of artificial intelligence that focuses on building models that can learn from data and make predictions or decisions without being explicitly programmed. \n",
    "                            It is commonly used for tasks likelassification, regression, and pattern recognition. \"\"\", \n",
    "            \"tool_call_id\": \"1\"},\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "GraderDocumentAgent(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098f4f2",
   "metadata": {},
   "source": [
    "## 6) Generate answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6acf208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateAnswer(state: MyState) :\n",
    "    \"\"\"Generate an answer.\"\"\"\n",
    "\n",
    "    GENERATE_PROMPT = \"\\n\".join([\n",
    "        \"You are an assistant for question-answering tasks.\",\n",
    "        \"Use the following pieces of retrieved context to answer the question.\",\n",
    "        \"- you must first understand the question and the context to answer correctly.\",\n",
    "        \"Answer as many questions as possible and make it a simple temporary one.\",\n",
    "        \"- Generate english text only.\",\n",
    "        \"- If the question is a greeting or introductory (like 'how are you', 'what's up', 'hello', 'hi', or self-introduction like 'I am X'), do not use the context. Instead, just greet back politely and say 'How can I help you?'.\",\n",
    "        \"- If it is a normal question, add some information from the context in your answer to make it complete, not only from the context.\",\n",
    "        \"Question: {question}\\n\",\n",
    "        \"Context: {context}\"\n",
    "    ])\n",
    "\n",
    "    user_messages = [m for m in state[\"messages\"] if isinstance(m,HumanMessage)]\n",
    "    \n",
    "    question = state.get(\"translated_query\", user_messages[-1].content)\n",
    "    context = state[\"messages\"][-1].content\n",
    "\n",
    "    prompt = GENERATE_PROMPT.format(question=question, context=context)\n",
    "    response = llm.invoke([{\"role\": \"user\", \n",
    "                            \"content\": prompt}])\n",
    "    \n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9ae8b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What are the main types of machine learning?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"retrieve_tool\",\n",
    "                        \"args\": {\"query\": \"types of machine learning\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": \"Machine learning is commonly categorized into three main types: supervised learning, unsupervised learning, and reinforcement learning.\",\n",
    "                \"tool_call_id\": \"1\",\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "response = GenerateAnswer(input)\n",
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1cd65",
   "metadata": {},
   "source": [
    "## 7) Chit-Chat Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68f00c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "def chitChatAgent(state : MyState):\n",
    "    user_messages= [m for m in state['messages'] if isinstance(m,HumanMessage)]\n",
    "    question = state.get(\"translated_query\", user_messages[-1].content)\n",
    "\n",
    "    msg_prompt = f\"\"\"\n",
    "        You are a Chit-Chat Assistant.\n",
    "        Your task: reply politely when the context not related to  a user question so follow Instructions to senf a chit chat message.\n",
    "        \n",
    "        Instructions:\n",
    "        1. Start by apologizing that you don't fully understand the question.\n",
    "        2. Try to clarify by highlighting key words from the user's question.\n",
    "        3. Use short, simple sentences to suggest that the user rephrase their question.\n",
    "        5. shorts apologizing messages in first sentence only.\n",
    "        6. write in english text only.\n",
    "        7. don't require any language from user to write his question.\n",
    "        8. ask only some question trying to understand user question\n",
    "        \n",
    "\n",
    "        User question: \"{question}\"\n",
    "        \"\"\"\n",
    "\n",
    "    prompt_msg_template = PromptTemplate(\n",
    "        template=msg_prompt,\n",
    "        input_variables=['question']\n",
    "    )\n",
    "\n",
    "    resonong = llm.invoke([{'role': 'user', 'content': prompt_msg_template.format(question=question)}])\n",
    "\n",
    "    return {'messages': [AIMessage(content=resonong.content)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "790dde26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I apologize, but I'm not entirely sure I understand your question. You mentioned \"salaj\" and \"zamilk\". Could you please rephrase it? Are you asking about a specific player or a team?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"where salaj play in zamilk\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"retrieve_tool\",\n",
    "                        \"args\": {\"query\": \"classification of machine learning\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\"role\": \"tool\", \"content\": \"Supervised, Unsupervised, Reinforcement Learning\", \"tool_call_id\": \"1\"},\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "response = chitChatAgent(input)\n",
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "985f5d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I apologize, but I don't fully understand your question. I'm having difficulty understanding the words you've used. Could you please try to rephrase it? What are you trying to ask about?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"اين كنت وين ياولا\",\n",
    "            }\n",
    "           \n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "response = chitChatAgent(input)\n",
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e3fa4",
   "metadata": {},
   "source": [
    "## 8)  Translate Agent\n",
    "\n",
    "- Translate the reasoning into the same **language** and **dialect** of the question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d68b95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TranslationReasoning(state: MyState):\n",
    "    \"\"\"Translate the reasoning into the same **language** and **dialect** of the question.\"\"\"\n",
    "\n",
    "    context = state[\"messages\"][-1].content\n",
    "    detected_lang = state.get(\"detected_lang\")\n",
    "    dialect = state.get(\"dialect\")\n",
    "\n",
    "\n",
    "    Translatetemplate = \"\\n\".join([\n",
    "        \"You are a translation agent. Your ONLY job is to translate English text into the target language below.\",\n",
    "        \"Never answer in Spanish, French, or any other language unless it exactly matches the detected language.\",\n",
    "        \"you must know we shortcut the two-character ISO 639-1 code for the language like ar for arabic , en for english \",\n",
    "        \"\",\n",
    "        f\"Target language: {detected_lang} \",\n",
    "        f\"Target dialect: {dialect or 'standard'}\",\n",
    "        \"\",\n",
    "        \"# Instructions:\",\n",
    "        \"- If dialect is None, translate to the language only.\",\n",
    "        \"- If the language is not English, keep important keywords in English.\",\n",
    "        \"- Don't explain, don't rephrase, just translate.\",\n",
    "        \"- If target language is Arabic, mimic the dialect if possible; otherwise use Modern Standard Arabic.\",\n",
    "        \"\",\n",
    "        \"Text to translate to targey language : \",\n",
    "        \"{context}\"\n",
    "    ])\n",
    "\n",
    "    TranslatePrompt = PromptTemplate(\n",
    "        template=Translatetemplate,\n",
    "        input_variables=[\"context\"],\n",
    "    )\n",
    "\n",
    "    prompt = TranslatePrompt.format(context=context)\n",
    "\n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": \"You are a strict translation agent. Respond ONLY with the translated text.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    translated_text = response.content \n",
    "    return {\"messages\": [AIMessage(content=translated_text)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f5a093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Translation Output ================\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "إزيك يا إسلام! أنا كويس، شكراً إنك سألت! إزاي أقدر أساعدك؟\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"Hello Islam! I'm doing well, thank you for asking! How can I help you?\")  \n",
    "    ],\n",
    "    \"detected_lang\": \"ar\",    \n",
    "    \"dialect\": \"EGY\"        \n",
    "}\n",
    "\n",
    "result = TranslationReasoning(test_state)\n",
    "\n",
    "print(\"\\n================ Translation Output ================\\n\")\n",
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f629be",
   "metadata": {},
   "source": [
    "# Work Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e6d8d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "workflow = StateGraph(MyState)\n",
    "\n",
    "workflow.add_node(\"DetectLangAgent\", detecting_language)\n",
    "workflow.add_node(\"Translate_Query\", TranslateQuery)\n",
    "workflow.add_node(\"RetriverAgent\", RetriverAgent)\n",
    "workflow.add_node(\"Chit-ChatAgent\", chitChatAgent)\n",
    "workflow.add_node(\"AnswerAgent\", GenerateAnswer)\n",
    "workflow.add_node(\"TranslationReasoning\", TranslationReasoning)\n",
    "\n",
    "workflow.add_edge(START, \"DetectLangAgent\")\n",
    "workflow.add_edge(\"DetectLangAgent\", \"Translate_Query\")\n",
    "workflow.add_edge(\"Translate_Query\", \"RetriverAgent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"RetriverAgent\",\n",
    "    GraderDocumentAgent,\n",
    "    {\n",
    "        \"AnswerAgent\": \"AnswerAgent\",\n",
    "        \"Chit-ChatAgent\": \"Chit-ChatAgent\",\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"AnswerAgent\", \"TranslationReasoning\")\n",
    "workflow.add_edge(\"Chit-ChatAgent\", \"TranslationReasoning\")\n",
    "workflow.add_edge(\"TranslationReasoning\", END)\n",
    "\n",
    "graph = workflow.compile(checkpointer=MemorySaver())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2db6ac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000002144A025B50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a2cf54df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "اذيك ياصحبي انا اسلام عامل اي\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "اذيك ياصحبي انا اسلام عامل اي\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: DetectLangAgent\n",
      "\n",
      "Detected language: ar\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How are you, my friend? I am Islam, how are you doing?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How are you, my friend? I am Islam, how are you doing?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: RetriverAgent\n",
      "Tool Calls:\n",
      "  retriever_tool (da4e8f24-3b5f-4963-b156-3f01c3fa4286)\n",
      " Call ID: da4e8f24-3b5f-4963-b156-3f01c3fa4286\n",
      "  Args:\n",
      "    query: How are you, my friend? I am Islam, how are you doing?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retriever_tool\n",
      "\n",
      "word “negative” to see which is higher:\n",
      "P(positivejThe sentiment of the sentence ``I like Jackie Chan\" is: )\n",
      "P(negativejThe sentiment of the sentence ``I like Jackie Chan\" is: )\n",
      "If the word “positive” is more probable, we say the sentiment of the sentence is\n",
      "positive, otherwise we say the sentiment is negative.\n",
      "We can also cast more complex tasks as word prediction. Consider question\n",
      "answering, in which the system is given a question (for example a question with\n",
      "a simple factual answer) and must give a textual answer; we introduce this task in\n",
      "\n",
      "people in this class, I just encourage you again to start to form project partners, to try to \n",
      "find project partners to do your project with. And also, this is a good time to start forming \n",
      "study groups, so either talk to your friends  or post in the newsgroup, but we just \n",
      "encourage you to try to star t to do both of those today, okay? Form study groups, and try \n",
      "to find two other project partners.  \n",
      "So thank you. I'm looking forward to teaching this class, and I'll see you in a couple of \n",
      "days.  [End of Audio]  \n",
      "Duration: 69 minutes  \n",
      "MachineLearning-Lecture02\n",
      "\n",
      "E5+……………\n",
      "U\n",
      "U\n",
      "U\n",
      "U…logitslogitslogitslogitslogits…\n",
      "<latexit sha1_base64=\"q3ZgXDyG7qtkT7t8hT47RdlwYG4=\">AAAB+XicbVDLSsNAFJ3UV62vWHe6GVsEN5bERXUlBUVcVrAPaEqYTCft0MlMmJkIIQT8AT/CTRE3Cv6Ev+DfmLTdtPXAwOGcM9x7jxcyqrRl/RqFtfWNza3idmlnd2//wDwst5WIJCYtLJiQXQ8pwignLU01I91QEhR4jHS88W3ud56JVFTwJx2HpB+gIac+xUhnkmseXzhMDGHsJk6A9EgGiR4hPlZpWnLNqlWzpoCrxJ6TauP0tXw3qdw0XfPHGQgcBYRrzJBSPdsKdT9BUlPMSFpyIkVChMdoSJLp5ik8y6QB9IXMHtdwqi7kUKBUHHhZMl9PLXu5+J/Xi7R/3U8oDyNNOJ4N8iMGtYB5DXBAJcGaxRlBWNJsQ4hHSCKss7Ly0+3lQ1dJ+7Jm12v1x6yDezBDEZyACjgHNrgCDfAAmqAFMHgBE/AJvozEeDPejY9ZtGDM/xyBBRjff79pldo=</latexit>\u0000logythanks\n",
      "\n",
      "all the math and equations and so on  that I'll be doing in class.  \n",
      "There's also a newsgroup, su.class.cs229, also written on the handout. This is a \n",
      "newsgroup that's sort of a forum for people in  the class to get to  know each other and \n",
      "have whatever discussions you want to ha ve amongst yourselves. So the class newsgroup \n",
      "will not be monitored by the TAs and me. But this is a place for you to form study groups \n",
      "or find project partners or discuss homework problems and so on, and it's not monitored \n",
      "by the TAs and me. So feel free to ta lk trash about this class there.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: RetriverAgent\n",
      "\n",
      "I can't find it.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Islam! I am doing well, thank you for asking. How can I help you?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "إزيك يا إسلام! أنا كويس، شكراً إنك سألت. أقدر أساعدك إزاي؟\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "user_message = HumanMessage(content=\"اذيك ياصحبي انا اسلام عامل اي\")\n",
    "\n",
    "stream = graph.stream(\n",
    "    {\"messages\": [user_message]},\n",
    "    config ={\"configurable\": {\"thread_id\": \"6\"}},\n",
    "    stream_mode=\"values\"  \n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if \"messages\" in chunk:\n",
    "        for msg in chunk[\"messages\"]:\n",
    "            msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8ae8d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 21\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 14\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 6\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "فك التشفير يعني اختيار كلمة لتوليدها تاليًا بناءً على احتمالات نموذج لغوي كبير للكلمات المحتملة والسياق الحالي.\n"
     ]
    }
   ],
   "source": [
    "output = graph.invoke( {\"messages\": [\n",
    "            HumanMessage(content=\" يعني اي decoding\") \n",
    "        ]} ,  config={\"configurable\": {\"thread_id\": \"6\"}})\n",
    "\n",
    "output['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ababcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='فك التشفير يعني اختيار كلمة لتوليدها تاليًا بناءً على احتمالات نموذج لغوي كبير للكلمات المحتملة والسياق الحالي.', additional_kwargs={}, response_metadata={})],\n",
       " 'detected_lang': 'ar',\n",
       " 'dialect': 'MSA'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51edcbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "An encoder-decoder model is an architecture that typically consists of two main parts: an encoder and a decoder.\n",
      "\n",
      "The **encoder** is used to provide a contextualized representation of input words or tokens, mapping a sequence of input embeddings to output embeddings of the same length, where the output vectors incorporate information from the entire input sequence. Bidirectional encoders, for example, generate these contextualized representations.\n",
      "\n",
      "The **decoder** is a generative part that uses the contextualized representation provided by the encoder to produce running text by decoding or sampling. This architecture was developed for tasks like handwriting generation and machine translation.\n",
      "\n",
      "In contrast, \"encoder-only\" models (like masked language models) produce an encoding for each input token but are generally not used for text generation, focusing instead on interpretative tasks. \"Decoder-only\" models correspond to just the generative decoder part of this overall architecture.\n"
     ]
    }
   ],
   "source": [
    "output = graph.invoke( {\"messages\": [\n",
    "            HumanMessage(content=\"what is encoder decoder\") \n",
    "        ]} ,  config={\"configurable\": {\"thread_id\": \"6\"}})\n",
    "\n",
    "output['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cadb85d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
