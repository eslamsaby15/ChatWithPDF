# ChatWith-Multi-PDFS / Docs

A simple **Chat with Multiple PDFs / Docs** app for **Retrieval-Augmented Generation (RAG)**.  
It allows you to ask questions about the contents of PDFs and DOC files, and the app AI-powered answers based on relevant responses.

![Chatbot Diagram](/src/images/GraghWorkFlow.jpg)

This app is built using [**LangGraph**](https://www.langchain.com/langgraph) and [**LangChain**](https://www.langchain.com/).



------
## ğŸš€ Features covered

- **Multi-Document Support**: Reads and processes both PDF and DOC files.  
- **Text Chunking**: Splits extracted text into manageable overlapping chunks.  
- **Semantic Embeddings**: Generates vector embeddings using state-of-the-art models.  
- **Vector Database**: Stores embeddings in a scalable vector DB for fast similarity search.  
- **Detection of Language and Dialect**: Automatically detects language and Arabic dialects if applicable.  
- **Retriever Tool**: Fetches the most relevant chunks using semantic search.  
- **Graders**: Evaluate the relevance of retrieved documents before generating answers.  
- **Translate & Reasoning**: Provides translation support and reasoning over queries.  
- **Query Handling**: Processes user queries for context-aware responses.  
- **LLM-Powered Answering**: Combines retrieved context with queries to generate factual, context-aware answers.  
- **Streamlit Integration**: Fully interactive interface for uploading documents and chatting with the AI assistant.
-----
## ğŸ”¹ Workflow

### 1. Language & Dialect Detection ğŸŒ
- Detect the language of the user query.
- Detect dialects if the query is in Arabic or other supported languages.
- Translate the query to English for processing.

### 2. Database Preparation ğŸ—‚ï¸
- Extract text from PDF/DOC files.
- Split text into smaller overlapping chunks.
- Generate embeddings and store them in the vector database.

### 3. Retrieval & Grading ğŸ”âš™ï¸
- Use the retriever tool to fetch relevant chunks based on the translated query.
- Graders evaluate the relevance of the retrieved chunks.
- Decide workflow:
  - **Generate Answer** â†’ if relevant chunks are found.
  - **Chitchat / fallback** â†’ if no relevant context is retrieved.

### 4. Answer Generation âœ¨
- Combine retrieved context (if any) with the translated query.
- Pass to the LLM â†’ produce answer in English.

### 5. Output Translation & Presentation ğŸŒ
- Translate the generated answer back to the original language and dialect of the query.
- Display the answer in Streamlit with proper formatting.

-----


# ğŸ“‚ ChatWithPDF - Structure

```bash
src/
â”‚   app.py
â”‚   requirements.txt
â”‚   workflow.ipynb
â”‚
â”œâ”€â”€â”€bins
â”‚   â”œâ”€â”€â”€core
â”‚   â”‚   â”œâ”€â”€ BaseState.py
â”‚   â”‚   â”œâ”€â”€ Chit_Chat.py
â”‚   â”‚   â”œâ”€â”€ Dectionlang.py
â”‚   â”‚   â”œâ”€â”€ Generation.py
â”‚   â”‚   â”œâ”€â”€ Grade.py
â”‚   â”‚   â”œâ”€â”€ ProcessingDocuments.py
â”‚   â”‚   â”œâ”€â”€ Retrieve.py
â”‚   â”‚   â”œâ”€â”€ TranslateQuery.py
â”‚   â”‚   â””â”€â”€ TranslateReasoning.py
â”‚   â”‚
â”‚   â”œâ”€â”€â”€stream_lit
â”‚   â”‚   â”œâ”€â”€ loadingFiles.py
â”‚   â”‚   â”œâ”€â”€ RunRag.py
â”‚   â”‚   â””â”€â”€ SetUP.py
â”‚   â”‚
â”‚   â””â”€â”€â”€WorkFlow
â”‚       â””â”€â”€ Graph.py
â”‚
â”œâ”€â”€â”€data/      
â”‚
â””â”€â”€â”€images/   

```
-----

## ğŸ“¦ Installation

### Requirements
- Python 3.11  

###  Install Python using MiniConda

1) Download and install MiniConda from [here](https://docs.anaconda.com/free/miniconda/#quick-command-line-install)  

2) Create a new environment:
```bash
conda create -n chat python=3.11
```

3) Activate the environment:
```bash
$ conda activate chat
```

4) Install the required packages
```bash
$ pip install -r requirements.txt
```

5) Setup the environment variables

```bash
$ cp .env.example .env
```

6) Run streamlit app
```bash
$ streamlit run app.py
```
-----------


![Chatbot ](/src/images/example.jpg)

---------
## ğŸ”¹ Conclusion  

- Demonstrates how **Chat with Multiple PDFs / Docs** pipeline can be built using **RAG (Retrieval-Augmented Generation)**.  

- Steps:  

  1. **Language & Dialect Detection** â†’ detect the user query language and dialect, translate to English for processing.  

  2. **Database Preparation** â†’ extract text from PDF/DOC files, split text into overlapping chunks, create embeddings, and store them in the vector database.  

  3. **Retrieval & Grading** â†’ fetch relevant chunks using the retriever tool, grade their relevance, and decide workflow:
     - **Generate Answer** â†’ if relevant chunks are found.
     - **Chitchat / fallback** â†’ if no relevant context is retrieved.  

  4. **Answer Generation** â†’ combine retrieved context with the translated query, generate the answer via LLM.  

  5. **Output Translation & Presentation** â†’ translate the generated answer back to the original language and dialect, display it in Streamlit with proper formatting.  
---------

## ğŸ‘¨â€ğŸ’» Built by Eslam Sabry

concat
ğŸ”— [LinkedIn](https://www.linkedin.com/in/eslamsabryai)   ğŸ”— [Kaggle](https://www.kaggle.com/eslamsabryelsisi)  

